{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento Modelos\n",
    "\n",
    "### Alejandro Villanueva Noriega\n",
    "#### 01 de Septiembre de 2021\n",
    "###### Aplicación de técnicas de Machine Learning a la predicción de fallos de discos mediante el uso de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import StorageLevel, SparkConf\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler, PCA\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector, VectorUDT\n",
    "from sklearn.metrics import classification_report\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import LogisticRegression, LinearSVC, LinearSVCModel, RandomForestClassifier\n",
    "\n",
    "#Basics\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_attributes = ['smart_Reallocated_Sector_Ct_raw_value','smart_Power_Cycle_Count_raw_value',\n",
    "                        'smart_Reported_Uncorrect_raw_value', 'smart_Command_Timeout_raw_value',\n",
    "                        'smart_High_Fly_Writes_raw_value', 'smart_Offline_Uncorrectable_raw_value',\n",
    "                        'smart_UDMA_CRC_Error_Count_raw_value', 'label'\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('etl/etldone_1.parquet')\n",
    "#df = spark.read.parquet('etl/etldone.parquet') 7 dias lag\n",
    "#df = spark.read.parquet('etl/etldone_1.parquet') 1 dia lag\n",
    "#df = spark.read.parquet('etl/etldone_2.parquet') 2 dias lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df.select(important_attributes)\n",
    "#input_data = df.select(\"smart_Reallocated_Sector_Ct_raw_value\", \"label\")\n",
    "\n",
    "vecAssembler = VectorAssembler(outputCol=\"features\")\n",
    "\n",
    "vecAssembler.setInputCols(important_attributes[:7])\n",
    "#vecAssembler.setInputCols(important_attributes[:1])\n",
    "\n",
    "output = vecAssembler.transform(input_data).select(\"label\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data = df.select(important_attributes)\n",
    "#input_data = input_data.rdd.map(lambda x: (x[7], DenseVector(x[:7])))\n",
    "#output = spark.createDataFrame(input_data, [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withMean=True, withStd=True)\n",
    "scalerModel = scaler.fit(output)\n",
    "scaledData = scalerModel.transform(output).select('label', 'scaledFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledData = scaledData.withColumnRenamed('scaledFeatures', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledData = scaledData.select( \"features\", scaledData.label.cast(LongType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = scaledData.randomSplit([0.6,0.4], seed = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failDf = train.filter(train.label==1)\n",
    "nofailDf = train.filter(train.label==0)\n",
    "sampleRatio = float(failDf.count()) / float(train.count())\n",
    "nofailDfSampleDf = nofailDf.sample(False, sampleRatio, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nofailDfSampleDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.where('label=\"1\"').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = failDf.unionAll(nofailDfSampleDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.select(train.features, train.label.cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.createOrReplaceTempView(\"data55\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT COUNT(*) as L0 FROM data55 where label=0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT COUNT(*) as L1 FROM data55 where label=1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.createOrReplaceTempView(\"data56\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT COUNT(*) as L0 FROM data56 where label=0\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT COUNT(*) as L1 FROM data56 where label=1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=3, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(train)\n",
    "train_pca = model.transform(train).select(\"pcaFeatures\", 'label')\n",
    "train_pca = train_pca.withColumnRenamed(\"pcaFeatures\", 'features')\n",
    "train_pca.limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=3, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(test)\n",
    "test_pca = model.transform(test).select(\"pcaFeatures\",'label')\n",
    "test_pca = test_pca.withColumnRenamed(\"pcaFeatures\", 'features')\n",
    "test_pca.limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print train_pca.count()\n",
    "print test_pca.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, featuresCol='features', labelCol='label')\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(train_pca)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = lrModel.transform(train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = lrModel.transform(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "print 'Test Area Under ROC ' + str(evaluator.evaluate(predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "print 'Train Area Under ROC ' + str(evaluator.evaluate(predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder().addGrid(lr.regParam, [0.001,0.01])\n",
    "             .addGrid(lr.elasticNetParam, [0.0,0.5,1.0])\n",
    "             .addGrid(lr.maxIter, [20,30,100])\n",
    "             .addGrid(lr.threshold, [0.5])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_2 = cvModel.transform(test_pca)\n",
    "print 'Test Area Under ROC ' + str(evaluator.evaluate(predictions_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_2 = cvModel.transform(train_pca)\n",
    "print 'Train Area Under ROC ' + str(evaluator.evaluate(predictions_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print best_model._java_obj.getRegParam()\n",
    "print best_model._java_obj.getMaxIter()\n",
    "print best_model._java_obj.getElasticNetParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_lg = predictions_train_2.select('label', 'prediction').toPandas()\n",
    "confusion_matrix = pd.crosstab(ccm_lg['label'], ccm_lg['prediction'], rownames=['Actual'], colnames=['Prediccion'])\n",
    "print (confusion_matrix)\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"Blues\", fmt='g', cbar_kws={\"orientation\": \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_lg = predictions_test_2.select('label', 'prediction').toPandas()\n",
    "confusion_matrix = pd.crosstab(ccm_lg['label'], ccm_lg['prediction'], rownames=['Actual'], colnames=['Prediccion'])\n",
    "print (confusion_matrix)\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"Blues\", fmt='g', cbar_kws={\"orientation\": \"horizontal\"})\n",
    "plt.savefig('results/CM_LG_2DAYS.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(ccm_lg['label'], ccm_lg['prediction'], output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.plot(best_model.summary.roc.select('FPR').collect(),\n",
    "         best_model.summary.roc.select('TPR').collect())\n",
    "plt.xlabel('FP')\n",
    "plt.ylabel('TP')\n",
    "plt.savefig('results/ROC_LG_2DAYS.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(maxIter=10, regParam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvcModel = lsvc.fit(train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = lsvcModel.coefficients\n",
    "intercept = lsvcModel.intercept\n",
    "print(\"Some coefficients: \" + str(coefficients[250:300]))\n",
    "print(\"Intercept: \" + str(intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_SVM = lsvcModel.transform(train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_SVM = lsvcModel.transform(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "print 'Test Area Under ROC ' + str(evaluator.evaluate(predictions_test_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "print 'Train Area Under ROC ' + str(evaluator.evaluate(predictions_train_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Accuracy ' + str(predictions_test_SVM.filter(predictions_test_SVM.label == predictions_test_SVM.prediction).count()/float(predictions_test_SVM.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder().addGrid(lsvc.regParam, [ 0.1])\n",
    "                                       .addGrid(lr.maxIter, [1,5,10])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=lsvc, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_2_SVM = cvModel.transform(test_pca)\n",
    "print 'Test Area Under ROC ' + str(evaluator.evaluate(predictions_test_2_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_2_SVM = cvModel.transform(train_pca)\n",
    "print 'Train Area Under ROC ' + str(evaluator.evaluate(predictions_train_2_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Accuracy ' + str(predictions_test_2_SVM.filter(predictions_test_2_SVM.label == predictions_test_2_SVM.prediction).count()/float(predictions_test_2_SVM.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_SVM = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print best_model_SVM._java_obj.getRegParam()\n",
    "print best_model_SVM._java_obj.getMaxIter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_lg = predictions_train_2.select('label', 'prediction').toPandas()\n",
    "confusion_matrix = pd.crosstab(ccm_lg['label'], ccm_lg['prediction'], rownames=['Actual'], colnames=['Prediccion'])\n",
    "print (confusion_matrix)\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"Blues\", fmt='g', cbar_kws={\"orientation\": \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_svm = predictions_test_2_SVM.select('label', 'prediction').toPandas()\n",
    "confusion_matrix = pd.crosstab(ccm_svm['label'], ccm_svm['prediction'], rownames=['Actual'], colnames=['Prediccion'])\n",
    "print (confusion_matrix)\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"Blues\", fmt='g', cbar_kws={\"orientation\": \"horizontal\"})\n",
    "plt.savefig('results/CM_SVM_2DAYS.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(ccm_svm['label'], ccm_svm['prediction'], output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label', numTrees=100 )\n",
    "rfModel = rf.fit(train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_RF = rfModel.transform(train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_RF = rfModel.transform(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "print 'Test Area Under ROC ' + str(evaluator.evaluate(predictions_test_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "print 'Train Area Under ROC ' + str(evaluator.evaluate(predictions_train_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Accuracy ' + str(predictions_test_RF.filter(predictions_test_RF.label == predictions_test_RF.prediction).count()/float(predictions_test_RF.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [50,100,150,300])\n",
    "             .addGrid(rf.maxDepth, [1,2,3])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_2 = cvModel.transform(test_pca)\n",
    "print 'Test Area Under ROC ' + str(evaluator.evaluate(predictions_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_2 = cvModel.transform(train_pca)\n",
    "print 'Train Area Under ROC ' + str(evaluator.evaluate(predictions_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_RF = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print best_model_RF._java_obj.getMaxDepth()\n",
    "print best_model_RF._java_obj.getNumTrees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_lg = predictions_train_2.select('label', 'prediction').toPandas()\n",
    "confusion_matrix = pd.crosstab(ccm_lg['label'], ccm_lg['prediction'], rownames=['Actual'], colnames=['Prediccion'])\n",
    "print (confusion_matrix)\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"Blues\", fmt='g', cbar_kws={\"orientation\": \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_lg = predictions_test_2.select('label', 'prediction').toPandas()\n",
    "confusion_matrix = pd.crosstab(ccm_lg['label'], ccm_lg['prediction'], rownames=['Actual'], colnames=['Prediccion'])\n",
    "print (confusion_matrix)\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"Blues\", fmt='g', cbar_kws={\"orientation\": \"horizontal\"})\n",
    "plt.savefig('results/CM_RF_UNDER.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(ccm_lg['label'], ccm_lg['prediction'], output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(report).transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
