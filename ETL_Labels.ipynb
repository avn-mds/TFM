{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('hdd_replaced_dataset.csv', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----+\n",
      "|  replaced|                node|disk|\n",
      "+----------+--------------------+----+\n",
      "|1520290800|c14.10.bd.cluster...| sde|\n",
      "|1525039200|c14.4.bd.cluster....| sdf|\n",
      "+----------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----+\n",
      "|  replaced|                node|disk|\n",
      "+----------+--------------------+----+\n",
      "|1520290800|c14.10.bd.cluster...| sde|\n",
      "|1525039200|c14.4.bd.cluster....| sdf|\n",
      "|1525039200|c14.9.bd.cluster....| sdb|\n",
      "|1525644000|c14.10.bd.cluster...| sdf|\n",
      "|1528927200|c13.15.node.int.c...| sdb|\n",
      "|1529013600|c13.14.node.int.c...| sdd|\n",
      "|1528754400|c14.1.bd.cluster....| sdj|\n",
      "|1531432800|c13.13.node.int.c...| sdg|\n",
      "|1532728800|c14.3.bd.cluster....| sdl|\n",
      "|1532815200|c14.6.bd.cluster....| sdh|\n",
      "|1532901600|c14.9.bd.cluster....| sde|\n",
      "|1543878000|c13.13.node.int.c...| sdj|\n",
      "|1543878000|c13.13.node.int.c...| sdb|\n",
      "|1544569200|c13.7.node.int.ce...| sdf|\n",
      "|1545001200|c14.8.bd.cluster....| sde|\n",
      "|1545001200|c14.12.bd.cluster...| sdj|\n",
      "|1545260400|c14.11.bd.cluster...| sdl|\n",
      "|1545606000|c14.12.bd.cluster...| sde|\n",
      "|1545865200|c14.5.bd.cluster....| sdj|\n",
      "|1545865200|c14.14.bd.cluster...| sdd|\n",
      "+----------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"timestamp\", from_unixtime(\"replaced\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----+-------------------+\n",
      "|  replaced|                node|disk|          timestamp|\n",
      "+----------+--------------------+----+-------------------+\n",
      "|1520290800|c14.10.bd.cluster...| sde|2018-03-06 00:00:00|\n",
      "|1525039200|c14.4.bd.cluster....| sdf|2018-04-30 00:00:00|\n",
      "|1525039200|c14.9.bd.cluster....| sdb|2018-04-30 00:00:00|\n",
      "|1525644000|c14.10.bd.cluster...| sdf|2018-05-07 00:00:00|\n",
      "|1528927200|c13.15.node.int.c...| sdb|2018-06-14 00:00:00|\n",
      "|1529013600|c13.14.node.int.c...| sdd|2018-06-15 00:00:00|\n",
      "|1528754400|c14.1.bd.cluster....| sdj|2018-06-12 00:00:00|\n",
      "|1531432800|c13.13.node.int.c...| sdg|2018-07-13 00:00:00|\n",
      "|1532728800|c14.3.bd.cluster....| sdl|2018-07-28 00:00:00|\n",
      "|1532815200|c14.6.bd.cluster....| sdh|2018-07-29 00:00:00|\n",
      "|1532901600|c14.9.bd.cluster....| sde|2018-07-30 00:00:00|\n",
      "|1543878000|c13.13.node.int.c...| sdj|2018-12-04 00:00:00|\n",
      "|1543878000|c13.13.node.int.c...| sdb|2018-12-04 00:00:00|\n",
      "|1544569200|c13.7.node.int.ce...| sdf|2018-12-12 00:00:00|\n",
      "|1545001200|c14.8.bd.cluster....| sde|2018-12-17 00:00:00|\n",
      "|1545001200|c14.12.bd.cluster...| sdj|2018-12-17 00:00:00|\n",
      "|1545260400|c14.11.bd.cluster...| sdl|2018-12-20 00:00:00|\n",
      "|1545606000|c14.12.bd.cluster...| sde|2018-12-24 00:00:00|\n",
      "|1545865200|c14.5.bd.cluster....| sdj|2018-12-27 00:00:00|\n",
      "|1545865200|c14.14.bd.cluster...| sdd|2018-12-27 00:00:00|\n",
      "+----------+--------------------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('replaced', 'string'),\n",
       " ('node', 'string'),\n",
       " ('disk', 'string'),\n",
       " ('timestamp', 'string')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.withColumn(\"timestamp\", to_date(\"timestamp\", format='yyyy-MM-dd HH:mm:ss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('replaced', 'string'),\n",
       " ('node', 'string'),\n",
       " ('disk', 'string'),\n",
       " ('timestamp', 'string')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----+-------------------+\n",
      "|  replaced|                node|disk|          timestamp|\n",
      "+----------+--------------------+----+-------------------+\n",
      "|1520290800|c14.10.bd.cluster...| sde|2018-03-06 00:00:00|\n",
      "|1525039200|c14.4.bd.cluster....| sdf|2018-04-30 00:00:00|\n",
      "|1525039200|c14.9.bd.cluster....| sdb|2018-04-30 00:00:00|\n",
      "|1525644000|c14.10.bd.cluster...| sdf|2018-05-07 00:00:00|\n",
      "|1528927200|c13.15.node.int.c...| sdb|2018-06-14 00:00:00|\n",
      "|1529013600|c13.14.node.int.c...| sdd|2018-06-15 00:00:00|\n",
      "|1528754400|c14.1.bd.cluster....| sdj|2018-06-12 00:00:00|\n",
      "|1531432800|c13.13.node.int.c...| sdg|2018-07-13 00:00:00|\n",
      "|1532728800|c14.3.bd.cluster....| sdl|2018-07-28 00:00:00|\n",
      "|1532815200|c14.6.bd.cluster....| sdh|2018-07-29 00:00:00|\n",
      "|1532901600|c14.9.bd.cluster....| sde|2018-07-30 00:00:00|\n",
      "|1543878000|c13.13.node.int.c...| sdj|2018-12-04 00:00:00|\n",
      "|1543878000|c13.13.node.int.c...| sdb|2018-12-04 00:00:00|\n",
      "|1544569200|c13.7.node.int.ce...| sdf|2018-12-12 00:00:00|\n",
      "|1545001200|c14.8.bd.cluster....| sde|2018-12-17 00:00:00|\n",
      "|1545001200|c14.12.bd.cluster...| sdj|2018-12-17 00:00:00|\n",
      "|1545260400|c14.11.bd.cluster...| sdl|2018-12-20 00:00:00|\n",
      "|1545606000|c14.12.bd.cluster...| sde|2018-12-24 00:00:00|\n",
      "|1545865200|c14.5.bd.cluster....| sdj|2018-12-27 00:00:00|\n",
      "|1545865200|c14.14.bd.cluster...| sdd|2018-12-27 00:00:00|\n",
      "+----------+--------------------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('replaced', 'string'),\n",
       " ('node', 'string'),\n",
       " ('disk', 'string'),\n",
       " ('timestamp', 'string')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['replaced']\n",
    "df = df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+\n",
      "|                node|disk|          timestamp|\n",
      "+--------------------+----+-------------------+\n",
      "|c14.10.bd.cluster...| sde|2018-03-06 00:00:00|\n",
      "|c14.4.bd.cluster....| sdf|2018-04-30 00:00:00|\n",
      "|c14.9.bd.cluster....| sdb|2018-04-30 00:00:00|\n",
      "|c14.10.bd.cluster...| sdf|2018-05-07 00:00:00|\n",
      "|c13.15.node.int.c...| sdb|2018-06-14 00:00:00|\n",
      "|c13.14.node.int.c...| sdd|2018-06-15 00:00:00|\n",
      "|c14.1.bd.cluster....| sdj|2018-06-12 00:00:00|\n",
      "|c13.13.node.int.c...| sdg|2018-07-13 00:00:00|\n",
      "|c14.3.bd.cluster....| sdl|2018-07-28 00:00:00|\n",
      "|c14.6.bd.cluster....| sdh|2018-07-29 00:00:00|\n",
      "|c14.9.bd.cluster....| sde|2018-07-30 00:00:00|\n",
      "|c13.13.node.int.c...| sdj|2018-12-04 00:00:00|\n",
      "|c13.13.node.int.c...| sdb|2018-12-04 00:00:00|\n",
      "|c13.7.node.int.ce...| sdf|2018-12-12 00:00:00|\n",
      "|c14.8.bd.cluster....| sde|2018-12-17 00:00:00|\n",
      "|c14.12.bd.cluster...| sdj|2018-12-17 00:00:00|\n",
      "|c14.11.bd.cluster...| sdl|2018-12-20 00:00:00|\n",
      "|c14.12.bd.cluster...| sde|2018-12-24 00:00:00|\n",
      "|c14.5.bd.cluster....| sdj|2018-12-27 00:00:00|\n",
      "|c14.14.bd.cluster...| sdd|2018-12-27 00:00:00|\n",
      "+--------------------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abreviating_disk(x):\n",
    "    return \".\".join(x.split(\".\", 2)[:2])\n",
    "\n",
    "abreviating_disk_UDF = udf(lambda z: abreviating_disk(z),StringType())\n",
    "\n",
    "def etl_labels(df):\n",
    "    df = df.withColumn(\"timestamp\", from_unixtime(\"replaced\"))\n",
    "    #df = df.withColumn(\"timestamp\", to_date(\"timestamp\", format='yyyy-MM-dd HH:mm:ss'))\n",
    "    df = df.withColumn(\"node\", abreviating_disk_UDF(\"node\"))\n",
    "    columns_to_drop = ['replaced']\n",
    "    df = df.drop(*columns_to_drop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df = spark.read.csv('hdd_replaced_dataset.csv', header='true')\n",
    "df_processed = etl_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-------------------+\n",
      "|  node|disk|          timestamp|\n",
      "+------+----+-------------------+\n",
      "|c14.10| sde|2018-03-06 00:00:00|\n",
      "| c14.4| sdf|2018-04-30 00:00:00|\n",
      "| c14.9| sdb|2018-04-30 00:00:00|\n",
      "|c14.10| sdf|2018-05-07 00:00:00|\n",
      "|c13.15| sdb|2018-06-14 00:00:00|\n",
      "|c13.14| sdd|2018-06-15 00:00:00|\n",
      "| c14.1| sdj|2018-06-12 00:00:00|\n",
      "|c13.13| sdg|2018-07-13 00:00:00|\n",
      "| c14.3| sdl|2018-07-28 00:00:00|\n",
      "| c14.6| sdh|2018-07-29 00:00:00|\n",
      "| c14.9| sde|2018-07-30 00:00:00|\n",
      "|c13.13| sdj|2018-12-04 00:00:00|\n",
      "|c13.13| sdb|2018-12-04 00:00:00|\n",
      "| c13.7| sdf|2018-12-12 00:00:00|\n",
      "| c14.8| sde|2018-12-17 00:00:00|\n",
      "|c14.12| sdj|2018-12-17 00:00:00|\n",
      "|c14.11| sdl|2018-12-20 00:00:00|\n",
      "|c14.12| sde|2018-12-24 00:00:00|\n",
      "| c14.5| sdj|2018-12-27 00:00:00|\n",
      "|c14.14| sdd|2018-12-27 00:00:00|\n",
      "+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_processed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.toPandas().to_csv('labels_processed.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-------------------+\n",
      "|  node|disk|          timestamp|\n",
      "+------+----+-------------------+\n",
      "|c14.10| sde|2018-03-06 00:00:00|\n",
      "+------+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_processed.limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(node=u'c14.10', disk=u'sde', timestamp=u'2018-03-06 00:00:00')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.createOrReplaceTempView(\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|disk|\n",
      "+----+\n",
      "| sdd|\n",
      "| sdg|\n",
      "| sdc|\n",
      "| sdi|\n",
      "| sdh|\n",
      "| sdk|\n",
      "| sdf|\n",
      "| sda|\n",
      "| sde|\n",
      "| sdb|\n",
      "| sdj|\n",
      "| sdl|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select distinct disk from labels\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select node disk from labels\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                node|\n",
      "+--------------------+\n",
      "|c14.10.bd.cluster...|\n",
      "|c14.4.bd.cluster....|\n",
      "|c14.9.bd.cluster....|\n",
      "|c14.10.bd.cluster...|\n",
      "|c13.15.node.int.c...|\n",
      "|c13.14.node.int.c...|\n",
      "|c14.1.bd.cluster....|\n",
      "|c13.13.node.int.c...|\n",
      "|c14.3.bd.cluster....|\n",
      "|c14.6.bd.cluster....|\n",
      "|c14.9.bd.cluster....|\n",
      "|c13.13.node.int.c...|\n",
      "|c13.13.node.int.c...|\n",
      "|c13.7.node.int.ce...|\n",
      "|c14.8.bd.cluster....|\n",
      "|c14.12.bd.cluster...|\n",
      "|c14.11.bd.cluster...|\n",
      "|c14.12.bd.cluster...|\n",
      "|c14.5.bd.cluster....|\n",
      "|c14.14.bd.cluster...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('node')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
